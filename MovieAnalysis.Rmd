---
title: "Statistical Modeling: IMDB's User Movie Ratings Analysis"
author:
- Juan Borgnino (jb3852)
- Carolyn Morris (cm3491)
- Jose Ramirez (jdr2162)
- Manuel Rueda (mr3523)
date: "December 15, 2015"
abstract: |
  In this analysis we take IMDB's movie rating and descriptive data, combine it with the Academy Awards' Best Picture nominations, and identify the driving variables behind a highly rated movie. A number of linear and non-linear models are utilized for this purpose. We identify the budget being a relevant variable for movies on the Animation and Action genres, but not on the rest. For all movies, the number of votes was the best predictor, implying that more popular movies tend to be rated higher (or the other way around). The number of 'Best Picture' nominations seems to play a minor but significant role.
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=6, echo=FALSE, warning=FALSE, message=FALSE)
```

```{r Setup}
library("gettingtothebottom")
library("RCurl")
library("corrplot")
library("GGally")
library("reshape2")
library("plyr")
library("leaps")
```


```{r Data Processing}
data("moviebudgets")
## Remove the individual rating columns.
movies <- moviebudgets[, !names(moviebudgets) %in% c("r1","r2","r3","r4","r5","r6","r7","r8","r9","r10")]
movies$title <- as.character(movies$title)

## Oscar awards.
oscars <- read.csv("academy_awards.csv", stringsAsFactors = F)
oscars$Year2 <- as.numeric(substr(oscars$Year, 0, 4))
bestP <- oscars[oscars$Category == "Best Picture" & oscars$Year2 <= 2000,]
movies$nominated <- rep(0, nrow(movies))
movies[!is.na(match(gsub(", The", "", gsub('"', '', movies$title)), gsub("The ", "", bestP$Nominee))), "nominated"] =+ 1
```

\section{Data Sources}

Our dataset consists on movie rating and budget data for 5,183 films, scraped from the [Internet Movie Database](http://www.imdb.com/interfaces/) FTP site, paired with a historical list of Academy Awards Best Picture Nominations, retrieved from [Agg Data](https://www.aggdata.com/awards/oscar). Both data sources are legaly made available to the general public. For our analysis, we are interested in analyzing the interactions between IMDB ratings assigned by the general public and a list of other possible explainatory variables, which are listed on the following table.

------------------------------------------------------------
Variable  Description
--------- ---------------------------------------------------
title     Title of the movie.
 
year      Year the movie was released.
 
budget    Total budget (if known) in US dollars.
 
length    Length of movie (in minutes).

rating    Average IMDb user rating.
 
votes     Number of IMDb users who rated the movie.

mpaa      MPAA rating.
      
nominated Binary variable indicating if the movie was
          nominated for the 'Best Movie'.

genre     Binary variables indicating whether movie belongs
          to any of the following genres: action, animation,
          comedy, drama, documentary, romance, short.
------------------------------------------------------------

\section{Exploratory Data Analysis}

Before begining with the formal statistical analysis, it is necessary to perform exploratory analysis on the data to identify possible patterns. We begin by looking at the summary information for each of the variables.

```{r Summary Statistics}
summary(movies)
genres <- c("Action", "Animation", "Comedy", "Drama", "Documentary", "Romance", "Short")
```

We see a couple of interesting things here:

(1) 25% of the movies have received less than 70 votes. We will remove this lower quantile, as we want to focus our attention on those films for which a larger consensus has been reached.


```{r Data Cleaning}
## Assign numerical variable to mpaa.
mpMat <- data.frame(levels(movies$mpaa), c(1,4,2,3,5))
names(mpMat) <- c("mpaa","mpnum")
movies <- merge(movies, mpMat)
movies = movies[, !names(movies) %in% c('mpaa')]

## Remove movies with less than 100 votes.
movies <- movies[movies$votes >= 70,]

## Deflate budget variable.
infl <- read.csv("infl.csv", stringsAsFactors = F)
movies$adjBudget <- as.numeric(movies$budget / infl[match(movies$year, infl$Date),2] * 100, scientific=F)
movies = movies[, !names(movies) %in% c('budget')]

## Remove short films.
movies <- movies[movies$Short == 0,]
movies <- movies[, !names(movies) %in% c('Short')]

## Remove outlying "Voyna i mir".
movies <- movies[-which.max(movies$adjBudget),]

## Remove titles column.
movies <- movies[, !names(movies) %in% c('title')]
```

```{r EDA}
## All movies.
ggpairs(movies[c(3:6, 13:15)], 
        diag=list(continuous="density", discrete="bar"),
        axisLabels="none")

allCorr <- cor(movies[3:ncol(movies)])
allCorr["rating", abs(allCorr["rating",]) > 0.2]
corrplot(allCorr, type="upper", order="hclust", tl.col="black", tl.srt=45)
```

\section{Test of Independence}

```{r Test of Independence}

## Melt the data to make the genres more readable.
molten <- melt(movies, id.vars = c("title", "year", "length","rating", "votes", "adjBudget",
                                   "mpnum", "nominated"), variable.name = "genre")
molten <- molten[!molten$value == 0,]

## Loop to see on which genres budget, votes and rating are independent.
## This is equivalent to the cor.test function.
voteTest <- function(x) {
  r <- cor(x$rating, x$votes)
  t <- (r * sqrt(nrow(x)-2)) / (sqrt(1-r^2))
  o <- data.frame(r,t, qt(0.05/2, nrow(x)-2), nrow(x), abs(t) > abs(qt(0.05/2, nrow(x)-2)),1 - pt(t, nrow(x)-2))
  colnames(o) <- c("r", "t", "t-crit", "n", "sig?", "p-value")
  o
}

budgetTest <- function(x) {
  r <- cor(x$rating, x$adjBudget)
  t <- (r * sqrt(nrow(x)-2)) / (sqrt(1-r^2))
  o <- data.frame(r,t, qt(0.05/2, nrow(x)-2), nrow(x), abs(t) > abs(qt(0.05/2, nrow(x)-2)), 1 - pt(t, nrow(x)-2))
  colnames(o) <- c("r", "t", "t-crit", "n", "sig?", "p-value")
  o
}

oscarTest <- function(x) {
  r <- cor(x$rating, x$nominated)
  t <- (r * sqrt(nrow(x)-2)) / (sqrt(1-r^2))
  o <- data.frame(r,t, qt(0.05/2, nrow(x)-2), nrow(x), abs(t) > abs(qt(0.05/2, nrow(x)-2)), 1 - pt(t, nrow(x)-2))
  colnames(o) <- c("r", "t", "t-crit", "n", "sig?", "p-value")
  o
}

corrs <- ddply(.data=molten, .variables=.(genre), .fun=voteTest)
print("rating vs. votes")
corrs

corrs <- ddply(.data=molten, .variables=.(genre), .fun=budgetTest)
print("rating vs. budget")
corrs

corrs <- ddply(.data=molten, .variables=.(genre), .fun=oscarTest)
print("rating vs. oscar")
corrs
```


```{r (TRASH) best subset selection test}
#Create Training set
set.seed(1)
train.index = sample(dim(movies)[1], round(dim(movies)[1]*0.8))
test.index = c(1:dim(movies)[1])[-c(train.index)]
train.set = movies[train.index, ]
test.set = movies[test.index, ]

#best subset selection and lm.
train.set2=movies[train.set$Animation==1 | train.set$Action==1,]
View(train.set2)
lm.fit=lm(rating~.+I(log(votes)),data =train.set2 )
summary(lm.fit)

train.set2 <- train.set2[, !names(movies) %in% c('Action', 'Animation','Comedy','Drama','Documentary',
                                                  'Romance')]

regfit.best=regsubsets(rating~. + I(log(votes)),data=train.set2, nvmax =dim(train.set2)[2])
reg.summary=summary(regfit.best)
print(reg.summary)
which.max(reg.summary$rsq)
```

\section{Modeling}

## Best Subset Selection
```{r}
library(ggplot2)
library(leaps)
mse.test.errors = vector()
inter.column=rep(1,dim(test.set)[1])

best.subset = regsubsets(rating ~., train.set, nvmax = 11)

```


We plot each model obtained using best subset selection againts the test MSE to obtain the best model of all
```{r}
for(i in 1:(dim(train.set)[2] - 1)){
  coef.best = coef(best.subset, id = i)
  predic = as.matrix(cbind(inter.column,test.set[ , names(test.set) %in% c(names(coef.best))])) %*% coef.best[] 
  errors = mean((test.set[,"rating"] - predic)^2)
  mse.test.errors = cbind(mse.test.errors, errors)
}
qplot(x = c(1:(dim(train.set)[2] - 1)), y = as.numeric(mse.test.errors), main = 'Test MSE vs Number of Predictors', xlab = 'Nr. of Predictors',
     ylab = 'Test MSE', geom = c("point", "path"))

```


This is the best model obtained. It includes variables year, length, votes, Action, Animation, Comedy,
Dramam, Documentary and adjBudget. As we can observe, all predictors are related to the response and we are obtaining an adjusted R squared value of 0.402, meaning that our model is explaining 40% of the variance of the rating, and a Test MSE of 1.092. However, plotting the residuals we find evidence of a non linear relationship between the predictors and the response. 
```{r}
lm.fit = lm(rating ~ year + length + votes + Action + Animation + Comedy
            + Drama + Documentary + adjBudget, data = train.set)
par(mfrow = c(2,2))
min(mse.test.errors)
summary(lm.fit)
plot(lm.fit)
```


We try taking the logarithm of the variables votes. We observe that there is no discernable pattern in the distribution of the errors. 
```{r}
lm.fit.log = lm(rating ~ year + length + I(log(votes)) + Action + Animation + Comedy
            + Drama + Documentary + adjBudget, data = train.set)
plot(lm.fit.log)
```

Finally, we also observe an important improvements in terms of Adjusted R squared, since it increased aprox 8%, and the Test MSE error I now 0.98.
```{r}
summary(lm.fit.log)
MSE.test = mean((test.set$rating - fit.log.predic)^2)
MSE.test
```

## Correlation Matrix


In our analysis, we explored four different methods for modeling the movie ratings: linear regression, polynomial regression, splines, and generalized additive models.

## Linear Regression

```{r}
# Using all variables as predictors
#lm.fit <- lm(rating ~., data = movies)
#summary(lm.fit)
# This uses titles, takes forever

# Remove titles
movies <- movies[-2]
lm.fit <- lm(rating ~., data = movies)
summary(lm.fit)
```

```{r}
# Using only votes
lm.fit <- lm(rating ~ votes, data = movies)
summary(lm.fit)

plot(votes, rating, pch = 20)
abline(lm.fit, lwd = 3, col = 'red')

# Consider only action and animation movies

```

## Polynomial Regression

We extend the linear regression model by replacing it with a polynomial function. We determine which degree polynomial to use with the Analysis of Variance (ANOVA). ANOVA uses hypothesis tests to select the degree of polynomial. The null hypothesis is that model M1 is sufficient to explain the data; the alternative hypothesis is that the more complex model M2 is required. Note that M1 and M2 must be nested models, i.e. M1 is a subset of M2. If the p-value is greater than 0.05, then there is not enough evidence to reject the null, and we conclude that the simpler model, M1, is sufficient to explain the data.

Log Votes
```{r}
fit.1 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + log.votes, data = movies)
fit.2 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + poly(log.votes, 2), data = movies)
fit.3 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + poly(log.votes, 3), data = movies)
fit.4 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + poly(log.votes, 4), data = movies)
fit.5 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + poly(log.votes, 5), data = movies)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
```



We use the model obtained to predict on our test set. We obtain a Test MSE of 0.936, which is an improvement from the model without the polynomial of degree 3.
```{r}
train.fit.3 = lm(rating ~ year + length + Action + Animation + Comedy
           + Drama + Documentary + adjBudget + poly(log(votes), 3), data = train.set)

test.fit.3 = predict(train.fit.3, newdata = test.set[, !names(test.set) %in% c('rating')])
MSE.test.fit.3 = mean((test.set$rating - test.fit.3)^2)
MSE.test.fit.3

```

The variable votes seems to be a very important variable to explain the response. We regress ratings onto a polynomial of degree 3 of votes and observe that the adjusted R square is of almost 20%. Hence, we consider interesting to visualize how does this curve fit the response on a graph.
```{r}
lm.log.votes.3 = lm(rating ~ poly(log.votes,3), data = movies)
summary(lm.log.votes.3)

```

```{r}

```

par(mfrow = c(1,1))
poly.fit = lm(rating ~ poly(log.votes, 3), data = movies)
vote.lims = range(movies$log.votes)
vote.grid = seq(from=vote.lims [1], to=vote.lims[2]) 

summary(poly.fit)

predict = predict(poly.fit, newdata = list(log.votes = vote.grid), se = T)
se.bands = cbind(predict$fit + 2*predict$se,  predict$fit - 2*predict$se)

plot(movies$log.votes, movies$rating, col = 'darkgrey', xlab = 'Votes', ylab = 'Rating', main = 'Votes vs Rating')
lines(vote.grid, predict$fit, lwd = 2, col = 'blue')
matlines(vote.grid, se.bands, lwd = 2, col = 'red')








The best model using log(votes) is cubic.

```{r}
summary(fit.3)
#predict(fit.3, interval = 'confidence')
```
R-squared: 0.19 --> explains 19% of the data

Log Budget
```{r}
fit.1 = lm(rating ~ log(adjBudget), data = movies)
fit.2 = lm(rating ~ poly(log(adjBudget), 2), data = movies)
fit.3 = lm(rating ~ poly(log(adjBudget), 3), data = movies)
fit.4 = lm(rating ~ poly(log(adjBudget), 4), data = movies)
fit.5 = lm(rating ~ poly(log(adjBudget), 5), data = movies)
anova(fit.1,fit.2,fit.3,fit.4,fit.5)
```
The best model using log(adjBudget) is cubic.

```{r}
summary(fit.3)
```
R-squared: 0.02 --> explains 2% of the data

## Step Functions

## Splines

## GAMs


# Which model was the best?


